{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix and Vocabulary Construction - Code reuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from scipy import sparse\n",
    "\n",
    "import nltk\n",
    "from nltk import bigrams\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = pd.read_csv(\"./estadao_noticias_eleicao.csv\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = news.titulo + \" \" + news.subTitulo + \" \" + news.conteudo\n",
    "content = content.fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def co_occurrence_matrix(corpus):\n",
    "    vocab = set(corpus)\n",
    "    vocab = list(vocab)\n",
    "    n = len(vocab)\n",
    "   \n",
    "    vocab_to_index = {word:i for i, word in enumerate(vocab)}\n",
    "    \n",
    "    bi_grams = list(bigrams(corpus))\n",
    "\n",
    "    bigram_freq = nltk.FreqDist(bi_grams).most_common(len(bi_grams))\n",
    "\n",
    "    I=list()\n",
    "    J=list()\n",
    "    V=list()\n",
    "    \n",
    "    for bigram in bigram_freq:\n",
    "        current = bigram[0][1]\n",
    "        previous = bigram[0][0]\n",
    "        count = bigram[1]\n",
    "\n",
    "        I.append(vocab_to_index[previous])\n",
    "        J.append(vocab_to_index[current])\n",
    "        V.append(count)\n",
    "        \n",
    "    co_occurrence_matrix = sparse.coo_matrix((V,(I,J)), shape=(n,n))\n",
    "\n",
    "    return co_occurrence_matrix, vocab_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove punctuation\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "tokens_lists = content.apply(lambda text: tokenizer.tokenize(text.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove stopwords\n",
    "stopword_ = stopwords.words('portuguese')\n",
    "filtered_tokens = tokens_lists.apply(lambda tokens: [token for token in tokens if token not in stopword_])\n",
    "\n",
    "#Transforming list of lists into one list\n",
    "tokens = [token for tokens_list in filtered_tokens for token in tokens_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix, vocab = co_occurrence_matrix(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consult Bigram Frequency - Code reuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "consultable_matrix = matrix.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consult_frequency(w1, w2):\n",
    "    return(consultable_matrix[vocab[w1],vocab[w2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example - Code reuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = 'neves'\n",
    "w2 = 'magela'\n",
    "consult_frequency(w1, w2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Escreva uma função que receba um certo termo de consulta e a matriz construída no passo 1 acima e retorne as top-3 palavras em ordem decrescente de frequencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildSortedList(expression):\n",
    "    d = {}\n",
    "    mostRecurrentWords = []\n",
    "    #INDICES E DADOS POSSUEM NECESSARIAMENTE O MESMO TAMANHO.\n",
    "    #INDICES RECUPERA OS INDICES DAS PALAVRAS ASSOCIADAS AO ARGUMENTO EXPRESSION\n",
    "    indices = consultable_matrix[vocab[expression]].indices\n",
    "    #DADOS É A QUANTIDADE DE VEZES QUE A PALAVRA ESTA ASSOCIADA\n",
    "    dados = consultable_matrix[vocab[expression]].data\n",
    "    #VARRER O DICIONARIO DE PALAVRAS, BUSCAR A PALAVRA PELO INDICE E ASSOCIAR A ELA \n",
    "    #A QUANTIDADE DE VEZES QUE APARECE EM UM NOVO DICIONARIO\n",
    "    contador = 0\n",
    "    for x in indices:\n",
    "        d[list(vocab.keys())[list(vocab.values()).index(x)]] = dados[contador]\n",
    "        contador+=1\n",
    "    \n",
    "    sorted_d = sorted(d.items(), key=operator.itemgetter(1))\n",
    "    if len(sorted_d) > 2:\n",
    "        mostRecurrentWords.append(sorted_d[-1])\n",
    "        mostRecurrentWords.append(sorted_d[-2])\n",
    "        mostRecurrentWords.append(sorted_d[-3])\n",
    "    return mostRecurrentWords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O teste acima funciona da seguinte forma:\n",
    "Passo 1- Criação de um dicionario vazio para armazenar os ids das palavras como chave e a quantidade de ocorrencias dela como valor \n",
    "Passo 2- Recupero todos os indices do vocabulario associado a matriz e armazeno na lista indices\n",
    "Passo 3- Recupero a quantidade de vezes que a palavra está associada a expressão passada\n",
    "Passo 4- É criado um contador para auxiliar na iteração dado que o ID da palavra contida na lista de Indices tem na mesma posição na lista de dados a quantidade de ocorrencias. A medida que o apontador do laço vai passando, o contador é incrementado para refletir na lista de dados o valor correto associado ao id da palavra.\n",
    "Passo 5- O dicionario criado é ordenado de acordo com a quantidade de ocorrencia das palavras, que no nosso caso é o valor associado a chave.\n",
    "Passo 6- Verifica se a quantidade de palavras é maior que 2 para que nao quebre ao acessar os ultimos indices da lista\n",
    "Passo 7- Retorna array com top3 palavras em ordem descrescente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTE: Retorno esperado: Rousseff, é, disse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'rousseff', 2903), (u'\\xe9', 208), (u'disse', 201)]\n"
     ]
    }
   ],
   "source": [
    "expression = 'dilma'\n",
    "resultado = buildSortedList(expression)\n",
    "print (resultado)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expansão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildExpandedSortedList(words):\n",
    "    mostRecurrentWords = []\n",
    "    for x in words:\n",
    "        mostRecurrentWords.append(buildSortedList(x))\n",
    "    return mostRecurrentWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (buildExpandedSortedList(['dilma','rousseff', 'é', 'disse']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definição da função OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funcao or - funciona para mais de 2 termos\n",
    "def funcaoOr(termos, dicionarioFinal):\n",
    "    retorno = []\n",
    "    #transforma todos os termos em minusculo para uma busca mais precisa\n",
    "    lowerList = [x.lower() for x in termos]\n",
    "    for termo in lowerList:\n",
    "        for y in dicionarioFinal[termo]:\n",
    "            if y not in retorno:\n",
    "                retorno.append(y)\n",
    "    return retorno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHAMADA FUNÇÃO OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Codigo auxiliar:\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "#Recuperando o documento sem encode\n",
    "doc =  pd.read_csv(\"./estadao_noticias_eleicao.csv\")\n",
    "\n",
    "#Montar dicionario\n",
    "def montaDicionario(coluna):\n",
    "    dicionario = defaultdict(set)\n",
    "    for x in range(0, len(coluna) -1):\n",
    "        splitted = str(coluna[x]).split(' ')\n",
    "        for z in splitted: \n",
    "            dicionario[z.lower()].add(doc.idNoticia[x])\n",
    "    return dicionario\n",
    "\n",
    "#Criacao do dicionario com chaves sendo as palavras e valores os ids das noticais\n",
    "texto = doc.titulo + \" \" + doc.conteudo\n",
    "dicionarioPalavras = montaDicionario(texto)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retorno da funcao or é a saida com todos os ids. Para evidencia, executar o metodo abaixo:\n",
    "funcaoOr(['dilma', 'rousseff', 'é', 'disse'], dicionarioPalavras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quais os termos retornados para a expansão de cada consulta?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resposta: \n",
    "#Para dilma: rousseff, é, disse\n",
    "#Para rousseff: pt, candidata, afirmou\n",
    "#Para fez: questáo, críticas, campanha \n",
    "#Para disse: ainda, presidente, ter\n",
    "\n",
    "#Para evidencias, basta executar o print abaixo:\n",
    "print (buildExpandedSortedList(['dilma','rousseff', 'fez', 'disse']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Você acha que esses termos são de fato relacionados com a consulta original? Justifique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sim, ao meu ver, todas as palavras possuem um contexto e um relacionamento com a consulta original, fazendo com que as frases não percam a logica quando relacionamos palavra por palavra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare os documentos retornados para a consulta original com a consulta expandida. Quais resultados você acha que melhor capturam a necessidade de informação do usuário? Por que?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao meu ver, se desconsiderarmos na consulta expandida os termos que são genéricos, com por exemplo artigos ou verbos do tipo é, vai, etc., a consulta expandida traz resultados completos, pelo fato de trazer mais informações relacionadas com a palavra buscada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A expansão de consultas é mais adequada para melhorar o recall ou o precision? Por que?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O precision. Porque os dados retornados nas consultas, no caso do recall, aumenta a completude dos resultados, mas também traz dados inúteis aos olhos do usuário. Por outro lado, no caso do precision, os dados são mais precisos e se aproximam mais dos dados de interesse do usuário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
